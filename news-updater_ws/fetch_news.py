import requests
from bs4 import BeautifulSoup

# å®šä¹‰ç›®æ ‡æ–°é—»ç½‘ç«™
YAHOO_FINANCE_URL = "https://finance.yahoo.com"
BLOOMBERG_MARKETS_URL = "https://www.bloomberg.com/markets"

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'
}

def fetch_yahoo_news():
    """ æŠ“å–Yahoo Financeçš„æ–°é—» """
    response = requests.get(YAHOO_FINANCE_URL, headers=HEADERS)
    if response.status_code != 200:
        print("Failed to retrieve Yahoo Finance news page")
        return []

    soup = BeautifulSoup(response.text, 'html.parser')
    articles = soup.find_all('li', class_='js-stream-content')

    news_list = []
    for article in articles[:5]:  # åªæŠ“å–å‰5æ¡æ–°é—»ï¼Œé˜²æ­¢æ•°æ®è¿‡è½½
        title_tag = article.find('h3')
        link_tag = article.find('a')

        if not title_tag or not link_tag:
            continue

        title = title_tag.get_text(strip=True)
        link = link_tag['href']
        
        # Yahoo Financeçš„é“¾æ¥æœ‰æ—¶æ˜¯ç›¸å¯¹è·¯å¾„ï¼Œéœ€è¦è¡¥å…¨
        if not link.startswith('http'):
            link = YAHOO_FINANCE_URL + link

        # è·å–æ‘˜è¦ï¼ˆæœ‰äº›æ–‡ç« æ²¡æœ‰æ‘˜è¦ï¼‰
        summary = "No summary available"
        summary_tag = article.find('p')
        if summary_tag:
            summary = summary_tag.get_text(strip=True)

        news_list.append({
            'title': title,
            'url': link,
            'summary': summary
        })

    return news_list

def fetch_bloomberg_news():
    """ æŠ“å–Bloomberg Marketsçš„æ–°é—» """
    response = requests.get(BLOOMBERG_MARKETS_URL, headers=HEADERS)
    if response.status_code != 200:
        print("Failed to retrieve Bloomberg Markets news page")
        return []

    soup = BeautifulSoup(response.text, 'html.parser')
    articles = soup.find_all('article')  # Bloombergçš„æ–°é—»é€šå¸¸åœ¨ <article> æ ‡ç­¾ä¸­

    news_list = []
    for article in articles[:5]:  # åªæŠ“å–å‰5æ¡æ–°é—»
        title_tag = article.find('h3')
        link_tag = article.find('a')

        if not title_tag or not link_tag:
            continue

        title = title_tag.get_text(strip=True)
        link = link_tag['href']

        # Bloombergçš„é“¾æ¥æœ‰æ—¶æ˜¯ç›¸å¯¹è·¯å¾„ï¼Œéœ€è¦è¡¥å…¨
        if not link.startswith('http'):
            link = "https://www.bloomberg.com" + link

        # è·å–æ‘˜è¦ï¼ˆéƒ¨åˆ†æ–°é—»æ²¡æœ‰æ‘˜è¦ï¼‰
        summary = "No summary available"
        summary_tag = article.find('p')
        if summary_tag:
            summary = summary_tag.get_text(strip=True)

        news_list.append({
            'title': title,
            'url': link,
            'summary': summary
        })

    return news_list

def save_news(yahoo_news, bloomberg_news, file_name='latest_news.md'):
    """ ä¿å­˜æ–°é—»åˆ° Markdown æ–‡ä»¶ """
    with open(file_name, 'w', encoding='utf-8') as file:
        file.write("# ğŸ“° Latest Financial News\n\n")

        # Yahoo Finance æ–°é—»
        file.write("## Yahoo Finance\n\n")
        for news in yahoo_news:
            file.write(f"### {news['title']}\n")
            file.write(f"**Summary:** {news['summary']}\n\n")
            file.write(f"[Read more]({news['url']})\n\n")
            file.write("---\n\n")

        # Bloomberg Markets æ–°é—»
        file.write("## Bloomberg Markets\n\n")
        for news in bloomberg_news:
            file.write(f"### {news['title']}\n")
            file.write(f"**Summary:** {news['summary']}\n\n")
            file.write(f"[Read more]({news['url']})\n\n")
            file.write("---\n\n")

if __name__ == "__main__":
    yahoo_news = fetch_yahoo_news()
    bloomberg_news = fetch_bloomberg_news()
    save_news(yahoo_news, bloomberg_news)
    print('âœ… Successfully updated Yahoo Finance & Bloomberg news!')
